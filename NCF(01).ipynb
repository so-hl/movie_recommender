{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) neural collaborative filtering\n",
    "\n",
    "trad cf assumes interactions between users and items follow a linear pattern\n",
    "\n",
    "but ncf assumes nonlinear rship by learning user and movie embeddings through MLP (multi-layer perceptron)\n",
    "\n",
    "input layer: user, movie embeddings (vectors)\n",
    "\n",
    "hidden layers: concatenate user and movie embeddings, pass through MLP layers, learn nonlinear rship\n",
    "\n",
    "output layer: rating prediction or prob score of whether user likes the movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from torch) (0.8.3)\n",
      "Requirement already satisfied: jinja2 in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: sympy in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: filelock in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: networkx in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/maryamseraj/opt/anaconda3/lib/python3.8/site-packages (from networkx->torch) (4.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings data\n",
    "ratings = pd.read_csv(\"ratings.csv\")  # columns: userId, movieId, rating, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first entries from ratings\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop timestamp column\n",
    "ratings = ratings.drop(columns=[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode user and movie IDs as categorical indices\n",
    "user_ids = ratings[\"userId\"].unique()\n",
    "movie_ids = ratings[\"movieId\"].unique()\n",
    "\n",
    "user2idx = {user: idx for idx, user in enumerate(user_ids)}\n",
    "movie2idx = {movie: idx for idx, movie in enumerate(movie_ids)}\n",
    "\n",
    "ratings[\"userId\"] = ratings[\"userId\"].map(user2idx)\n",
    "ratings[\"movieId\"] = ratings[\"movieId\"].map(movie2idx)\n",
    "\n",
    "num_users = len(user2idx)\n",
    "num_movies = len(movie2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of movies: 9724\n"
     ]
    }
   ],
   "source": [
    "# Display number of users and number of movies\n",
    "print(f\"Number of users: {num_users}, Number of movies: {num_movies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NCF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    '''\n",
    "    Neural Collaborative Filtering (NCF) model.\n",
    "    Inherits from nn.Module (class): Base class for all neural network modules.\n",
    "    '''\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=32, hidden_dims=[64, 32]):\n",
    "        '''\n",
    "        Initialise the NCF model.\n",
    "        Args:\n",
    "            num_users (int): Number of unique users.\n",
    "            num_movies (int): Number of unique movies.\n",
    "            embedding_dim (int, optional): Dimensionality of user and movie embeddings. Defaults to 32.\n",
    "            hidden_dims (list, optional): List of hidden layer dimensions for the MLP. Defaults to [64, 32].\n",
    "        '''\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2  # Concatenated user-movie embeddings\n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1))  # Output layer\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        '''\n",
    "        Forward pass of the NCF model.\n",
    "        Args:\n",
    "            user_ids (torch.Tensor): Tensor of user IDs.\n",
    "            movie_ids (torch.Tensor): Tensor of movie IDs.\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted ratings.\n",
    "        '''\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        movie_emb = self.movie_embedding(movie_ids)\n",
    "        x = torch.cat([user_emb, movie_emb], dim=-1)\n",
    "        return self.mlp(x).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fine-tuning ncf  \n",
    "- pretrain (train on large dataset of movie interactions)  \n",
    "\n",
    "fine tune:  \n",
    "- adjust embedding layers separately for frequent vs infrequent users  \n",
    "- freeze earlier layers and train only later MLP layers on smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ratings)) # confirming ratings remains a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for movie ratings.\n",
    "    '''\n",
    "    def __init__(self, df):\n",
    "        '''\n",
    "        Initialise the dataset.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing movie ratings.\n",
    "        '''\n",
    "        self.users = torch.tensor(df[\"userId\"].values, dtype=torch.long)\n",
    "        self.movies = torch.tensor(df[\"movieId\"].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns:\n",
    "           size of ratings dataset\n",
    "        '''\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Args: \n",
    "            idx (integer): Index of the data point.\n",
    "        Returns: \n",
    "            tuple containing specifc user, movie, and rating tensors\n",
    "        '''\n",
    "        return self.users[idx], self.movies[idx], self.ratings[idx]  # Returns individual tensor elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will split the ratings dataset into pretraining data and finetuning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain NCF on a large dataset\n",
    "pretrain_model = NCF(num_users, num_movies)  # Initialise model\n",
    "pretrain_criterion = nn.MSELoss()\n",
    "pretrain_optimiser = optim.Adam(pretrain_model.parameters(), lr=0.001)\n",
    "\n",
    "# Split into large dataset (80%) for pretraining and small dataset (20%) for fine-tuning\n",
    "train_size = int(0.8 * len(ratings))\n",
    "fine_tune_size = len(ratings) - train_size\n",
    "\n",
    "# Now split the DataFrame:\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, fine_tune_df = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the dataset using indices instead of Subset objects\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, fine_tune_df = train_test_split(ratings, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_df), type(fine_tune_df)) \n",
    "print(type(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, pretrain the model using a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Loss: 3.2937\n",
      "Pretrain Epoch 2/5, Loss: 1.0006\n",
      "Pretrain Epoch 3/5, Loss: 0.9085\n",
      "Pretrain Epoch 4/5, Loss: 0.8550\n",
      "Pretrain Epoch 5/5, Loss: 0.8177\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "large_dataloader = DataLoader(MovieDataset(train_df), batch_size=512, shuffle=True)\n",
    "dataloader = DataLoader(MovieDataset(fine_tune_df), batch_size=256, shuffle=True)\n",
    "large_dataset, small_dataset = torch.utils.data.random_split(ratings, [train_size, fine_tune_size])\n",
    "\n",
    "epochs = 5  # Train for 5 epochs on a large dataset\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for users, movies, ratings in large_dataloader:  # Train on large dataset\n",
    "        pretrain_optimiser.zero_grad()\n",
    "        predictions = pretrain_model(users, movies)\n",
    "        loss = pretrain_criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        pretrain_optimiser.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Pretrain Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(large_dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load pretrained model for use in finetuning, then adjust for frequent vs. infrequent users.\n",
    "\n",
    "Also freeze earlier layers (embedding layers) in order to prevent overfitting.\n",
    "\n",
    "Increase the learning rate for MLP layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/15, Loss: 9.4465\n",
      "Fine-tune Epoch 2/15, Loss: 1.6925\n",
      "Fine-tune Epoch 3/15, Loss: 1.1916\n",
      "Fine-tune Epoch 4/15, Loss: 1.1413\n",
      "Fine-tune Epoch 5/15, Loss: 1.1070\n",
      "Unfroze embeddings at epoch 5\n",
      "Fine-tune Epoch 6/15, Loss: 1.0808\n",
      "Fine-tune Epoch 7/15, Loss: 1.0650\n",
      "Fine-tune Epoch 8/15, Loss: 1.0511\n",
      "Fine-tune Epoch 9/15, Loss: 1.0379\n",
      "Fine-tune Epoch 10/15, Loss: 1.0256\n",
      "Fine-tune Epoch 11/15, Loss: 1.0144\n",
      "Fine-tune Epoch 12/15, Loss: 1.0089\n",
      "Fine-tune Epoch 13/15, Loss: 1.0030\n",
      "Fine-tune Epoch 14/15, Loss: 0.9979\n",
      "Fine-tune Epoch 15/15, Loss: 0.9934\n"
     ]
    }
   ],
   "source": [
    "## fine-tuning code here\n",
    "# Load pretrained model for fine-tuning\n",
    "fine_tune_model = NCF(num_users, num_movies) \n",
    "fine_tune_criterion = nn.MSELoss()  # Define the loss function\n",
    "\n",
    "\n",
    "# use the original DataFrame to create dataloader (train_df in this case)\n",
    "for user_id, count in train_df[\"userId\"].value_counts().items():\n",
    "    if count < 10:  # Example threshold for infrequent users\n",
    "        fine_tune_model.user_embedding.weight.data[user_id] *= 0.5  # Scale down learning rate for them\n",
    "\n",
    "\n",
    "# Freeze earlier layers (embedding layers) (prevents overfitting)\n",
    "for param in fine_tune_model.user_embedding.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in fine_tune_model.movie_embedding.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "embedding_params = list(fine_tune_model.user_embedding.parameters()) + list(fine_tune_model.movie_embedding.parameters())\n",
    "mlp_params = list(fine_tune_model.mlp.parameters())\n",
    "\n",
    "fine_tune_optimiser = optim.Adam([\n",
    "    {'params': embedding_params, 'lr': 0.0001},  # Low LR for embeddings\n",
    "    {'params': mlp_params, 'lr': 0.0005}         # Higher LR for MLP layers\n",
    "])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(fine_tune_optimiser, step_size=5, gamma=0.5)  # Reduce LR every 5 epochs\n",
    "\n",
    "epochs = 15  # Fine-tune for 10 epochs\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    # Gradually Unfreeze Embeddings after 5 epochs\n",
    "    if epoch == 5:\n",
    "        for param in fine_tune_model.user_embedding.parameters():\n",
    "            param.requires_grad = True  # Unfreeze embeddings\n",
    "        for param in fine_tune_model.movie_embedding.parameters():\n",
    "            param.requires_grad = True  # Unfreeze embeddings\n",
    "        print(\"Unfroze embeddings at epoch 5\")\n",
    "      \n",
    "    \n",
    "    for users, movies, ratings in dataloader:\n",
    "        fine_tune_optimiser.zero_grad()\n",
    "        predictions = fine_tune_model(users, movies)\n",
    "        loss = fine_tune_criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        fine_tune_optimiser.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Fine-tune Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot our pretraining vs. finetuning results\n",
    "plt.hist(train_df[\"rating\"], bins=5, alpha=0.5, label=\"Pretraining\")\n",
    "plt.hist(fine_tune_df[\"rating\"], bins=5, alpha=0.5, label=\"Fine-Tuning\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Rating Distribution in Pretraining vs. Fine-Tuning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
